// test/analyze_topic_suggestion_test.dart
//
// Diagnostic test to analyze topic suggestion failure root cause
// Run with: dart test test/analyze_topic_suggestion_test.dart --reporter expanded

import 'dart:io';
import 'package:flutter/foundation.dart';
import 'package:mobile_rag_engine/mobile_rag_engine.dart';
import 'package:ollama_dart/ollama_dart.dart';

/// Run analysis to understand topic suggestion failures
void main() async {
  debugPrint('=' * 70);
  debugPrint('üìä TOPIC SUGGESTION FAILURE ANALYSIS');
  debugPrint('=' * 70);

  // DB path - same as app uses
  final homeDir = Platform.environment['HOME']!;
  final dbPath =
      '$homeDir/Library/Containers/com.example.localGemmaMacos/Data/Documents/local_gemma_rag.db';

  // Check if DB exists
  if (!File(dbPath).existsSync()) {
    debugPrint('‚ùå Database not found at: $dbPath');
    debugPrint('   Please run the app first to create the database.');
    return;
  }

  debugPrint('üìÅ Using DB: $dbPath\n');

  // 1. Get all chunks from database
  debugPrint('üìö STEP 1: Loading all chunks from database...');
  debugPrint('-' * 50);

  final allChunks = await getAllChunkIdsAndContents(dbPath: dbPath);
  debugPrint('   Total chunks: ${allChunks.length}');

  if (allChunks.isEmpty) {
    debugPrint('‚ùå No chunks found in database.');
    return;
  }

  // 2. Analyze chunk topics
  debugPrint('\nüìã STEP 2: Analyzing chunk content topics...');
  debugPrint('-' * 50);

  // Extract key topics by looking at chunk content
  final Set<String> allKeywords = {};
  for (final chunk in allChunks) {
    // Simple keyword extraction - look for nouns and key phrases
    final words = chunk.content
        .replaceAll(RegExp(r'[^\w\sÍ∞Ä-Ìû£]'), ' ')
        .split(RegExp(r'\s+'))
        .where((w) => w.length > 2)
        .toSet();
    allKeywords.addAll(words);
  }

  // Show sample chunks
  debugPrint('   Sample chunk contents (first 5):');
  for (var i = 0; i < allChunks.length && i < 5; i++) {
    final preview = allChunks[i].content.length > 100
        ? '${allChunks[i].content.substring(0, 100)}...'
        : allChunks[i].content;
    debugPrint('   [$i] ${preview.replaceAll('\n', ' ')}');
  }

  debugPrint('\n   Unique keywords extracted: ${allKeywords.length}');
  debugPrint('   Sample keywords: ${allKeywords.take(30).join(', ')}');

  // 3. Simulate LLM question generation
  debugPrint('\nü§ñ STEP 3: Generating questions via LLM...');
  debugPrint('-' * 50);

  final ollamaClient = OllamaClient();

  // Sample chunks (same logic as TopicSuggestionService)
  final sampledChunks = _sampleChunks(allChunks, 15);
  final sampleText = sampledChunks.map((c) => c.content).join('\n\n---\n\n');

  // Truncate like the service does
  final truncatedText = sampleText.length > 4000
      ? '${sampleText.substring(0, 4000)}...'
      : sampleText;

  debugPrint('   Sampled ${sampledChunks.length} chunks for analysis');
  debugPrint('   Total sample text length: ${truncatedText.length} chars');

  // Show sampled chunk text for debugging
  debugPrint('\n   üìú SAMPLED CHUNK TEXT (for LLM):');
  debugPrint('   ${'=' * 60}');
  debugPrint(truncatedText);
  debugPrint('   ${'=' * 60}');

  // Generate questions
  final candidateCount = 6;
  final prompt =
      '''ÏïÑÎûòÎäî ÏßÄÏãù Î≤†Ïù¥Ïä§Ïóê Ï†ÄÏû•Îêú Î¨∏ÏÑúÎì§Ïùò ÏÉòÌîåÏûÖÎãàÎã§. 
Ïù¥ ÎÇ¥Ïö©ÏùÑ Î∂ÑÏÑùÌïòÏó¨ ÏÇ¨Ïö©ÏûêÍ∞Ä Î¨ºÏñ¥Î≥º ÎßåÌïú Ïú†Ïö©Ìïú ÏßàÎ¨∏ $candidateCountÍ∞úÎ•º ÏÉùÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî.

Í∑úÏπô:
1. ÏßàÎ¨∏ÏùÄ Î∞òÎìúÏãú ÏïÑÎûò Î¨∏ÏÑúÏóêÏÑú ÏßÅÏ†ëÏ†ÅÏúºÎ°ú ÎãµÌï† Ïàò ÏûàÎäî ÎÇ¥Ïö©Ïù¥Ïñ¥Ïïº Ìï©ÎãàÎã§.
2. Î¨∏ÏÑúÏóê Î™ÖÏãúÏ†ÅÏúºÎ°ú Ïñ∏Í∏âÎêú ÏÇ¨Ïã§, Îç∞Ïù¥ÌÑ∞, Í∞úÎÖêÏóê ÎåÄÌï¥ ÏßàÎ¨∏ÌïòÏÑ∏Ïöî.
3. Î¨∏ÏÑúÏóê ÏóÜÎäî Ïô∏Î∂Ä Ï†ïÎ≥¥Î•º ÌïÑÏöîÎ°ú ÌïòÎäî ÏßàÎ¨∏ÏùÄ ÌîºÌïòÏÑ∏Ïöî.
4. ÏßàÎ¨∏ÏùÄ Í∞ÑÍ≤∞ÌïòÍ≤å ÏûëÏÑ±ÌïòÏÑ∏Ïöî (1-2Î¨∏Ïû•).
5. ÏßàÎ¨∏ÏùÄ ÌïúÍµ≠Ïñ¥Î°ú ÏûëÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî (Î¨∏ÏÑúÍ∞Ä ÌïúÍµ≠Ïñ¥Ïù∏ Í≤ΩÏö∞).

Î¨∏ÏÑú ÏÉòÌîå:
$truncatedText

JSON ÌòïÏãùÏúºÎ°úÎßå ÏùëÎãµÌïòÏÑ∏Ïöî:
[
  {"topic": "Ï£ºÏ†ú1", "question": "ÏßàÎ¨∏1?"},
  {"topic": "Ï£ºÏ†ú2", "question": "ÏßàÎ¨∏2?"}
]''';

  debugPrint('\n   üîÑ Calling Ollama for question generation...');

  try {
    final response = await ollamaClient.generateCompletion(
      request: GenerateCompletionRequest(
        model: 'gemma3:4b',
        prompt: prompt,
        options: const RequestOptions(temperature: 0.5, numPredict: 800),
      ),
    );

    final responseText = response.response?.trim() ?? '';
    debugPrint('\n   üìù LLM Response:');
    debugPrint('   ${responseText.replaceAll('\n', '\n   ')}');

    // Parse questions
    final questions = _parseQuestions(responseText);
    debugPrint('\n   Parsed ${questions.length} questions');

    // 4. Validate each question
    debugPrint('\nüîç STEP 4: Validating questions with RAG search...');
    debugPrint('-' * 50);

    // Initialize tokenizer and embedding model
    final tokenizerPath =
        '$homeDir/Library/Containers/com.example.localGemmaMacos/Data/Documents/tokenizer.json';
    await initTokenizer(tokenizerPath: tokenizerPath);

    // Load embedding model from assets
    final modelPath = '${Directory.current.path}/assets/bge-m3-int8.onnx';
    if (File(modelPath).existsSync()) {
      final modelBytes = await File(modelPath).readAsBytes();
      await EmbeddingService.init(modelBytes);
      debugPrint('   ‚úÖ Embedding model loaded');
    } else {
      debugPrint('   ‚ùå Embedding model not found at: $modelPath');
      debugPrint('   Skipping validation...');
      return;
    }

    // Initialize RAG service
    final ragService = SourceRagService(
      dbPath: dbPath,
      maxChunkChars: 500,
      overlapChars: 50,
    );
    await ragService.init();

    // Validate each question
    for (final q in questions) {
      debugPrint('\n   üìå Question: "${q['question']}"');
      debugPrint('      Topic: ${q['topic']}');

      // Search for the question
      final result = await ragService.search(
        q['question']!,
        topK: 5,
        tokenBudget: 500,
        adjacentChunks: 0,
      );

      debugPrint('      RAG Results:');

      if (result.chunks.isEmpty) {
        debugPrint('      ‚ùå NO CHUNKS FOUND');
        continue;
      }

      // Check if question keywords appear in chunks
      final questionWords = q['question']!
          .replaceAll(RegExp(r'[^\wÍ∞Ä-Ìû£]'), ' ')
          .split(RegExp(r'\s+'))
          .where((w) => w.length > 2)
          .toSet();

      for (var i = 0; i < result.chunks.length && i < 5; i++) {
        final chunk = result.chunks[i];
        final preview = chunk.content.length > 80
            ? '${chunk.content.substring(0, 80)}...'
            : chunk.content;

        // Count matching keywords
        final chunkWords = chunk.content
            .replaceAll(RegExp(r'[^\wÍ∞Ä-Ìû£]'), ' ')
            .toLowerCase()
            .split(RegExp(r'\s+'))
            .toSet();
        final matchingWords = questionWords
            .where((w) => chunkWords.contains(w.toLowerCase()))
            .toList();

        final matchIndicator = matchingWords.isEmpty
            ? '‚ùå NO MATCH'
            : '‚úÖ ${matchingWords.length} matches (${matchingWords.take(3).join(', ')})';

        debugPrint(
          '      [$i] sim=${chunk.similarity.toStringAsFixed(3)}: '
          '${preview.replaceAll('\n', ' ')}',
        );
        debugPrint('          $matchIndicator');
      }

      // Analysis
      final bestScore = result.chunks.isNotEmpty
          ? result.chunks
                .map((c) => c.similarity)
                .reduce((a, b) => a > b ? a : b)
          : 0.0;
      final highQualityCount = result.chunks
          .where((c) => c.similarity >= 0.5)
          .length;

      if (bestScore >= 0.5 && highQualityCount >= 2) {
        debugPrint(
          '      ‚úÖ PASSES validation (score: ${bestScore.toStringAsFixed(3)}, quality chunks: $highQualityCount)',
        );
      } else {
        debugPrint(
          '      ‚ùå FAILS validation (score: ${bestScore.toStringAsFixed(3)}, quality chunks: $highQualityCount)',
        );
      }
    }
  } catch (e, st) {
    debugPrint('   ‚ùå Error: $e');
    debugPrint('   Stack: $st');
  }

  debugPrint('\n${'=' * 70}');
  debugPrint('üìä ANALYSIS COMPLETE');
  debugPrint('=' * 70);
}

/// Sample chunks (same logic as TopicSuggestionService)
List<ChunkForReembedding> _sampleChunks(
  List<ChunkForReembedding> chunks,
  int sampleSize,
) {
  if (chunks.length <= sampleSize) {
    return chunks;
  }

  // Shuffle
  final shuffled = List<ChunkForReembedding>.from(chunks);
  shuffled.shuffle();

  // Sort by length (prefer longer chunks)
  shuffled.sort((a, b) => b.content.length.compareTo(a.content.length));

  // Take top half by length, shuffle again
  final topHalf = shuffled.take((shuffled.length / 2).ceil()).toList();
  topHalf.shuffle();

  return topHalf.take(sampleSize).toList();
}

/// Parse LLM response into questions
List<Map<String, String>> _parseQuestions(String responseText) {
  try {
    final jsonMatch = RegExp(r'\[[\s\S]*\]').firstMatch(responseText);
    if (jsonMatch == null) {
      debugPrint('   ‚ö†Ô∏è No JSON array found in response');
      return [];
    }

    final jsonStr = jsonMatch.group(0)!;

    // Manual JSON parsing since we don't have dart:convert in test
    final questions = <Map<String, String>>[];
    final itemRegex = RegExp(
      r'\{\s*"topic"\s*:\s*"([^"]+)"\s*,\s*"question"\s*:\s*"([^"]+)"\s*\}',
    );

    for (final match in itemRegex.allMatches(jsonStr)) {
      questions.add({'topic': match.group(1)!, 'question': match.group(2)!});
    }

    return questions;
  } catch (e) {
    debugPrint('   ‚ö†Ô∏è Failed to parse response: $e');
    return [];
  }
}
