/// Main entry point for Mobile RAG Engine.
///
/// Provides a singleton pattern for easy access throughout your app.
/// Initialize once in main(), use anywhere via [MobileRag.instance].
///
/// ## Quick Start
///
/// ```dart
/// import 'package:mobile_rag_engine/mobile_rag_engine.dart';
///
/// void main() async {
///   WidgetsFlutterBinding.ensureInitialized();
///
///   await MobileRag.initialize(
///     tokenizerAsset: 'assets/tokenizer.json',
///     modelAsset: 'assets/model.onnx',
///   );
///
///   runApp(const MyApp());
/// }
///
/// // Later, anywhere in your app:
/// final result = await MobileRag.instance.search('What is Flutter?');
/// ```
library;

import 'package:flutter/foundation.dart';
import 'package:mobile_rag_engine/services/rag_config.dart';
import 'package:mobile_rag_engine/services/rag_engine.dart';
import 'package:mobile_rag_engine/services/context_builder.dart';
import 'package:mobile_rag_engine/services/source_rag_service.dart';
// Explicitly import SourceEntry so it can be used in types
import 'package:mobile_rag_engine/src/rust/api/source_rag.dart'
    show SourceEntry, SourceStats;
import 'package:mobile_rag_engine/src/rust/api/hybrid_search.dart' as hybrid;

// Export types for consumers
export 'package:mobile_rag_engine/src/rust/api/source_rag.dart'
    show
        ChunkSearchResult,
        SourceStats,
        AddSourceResult,
        ChunkData,
        SourceEntry;

export 'package:mobile_rag_engine/services/text_chunker.dart';

/// Singleton facade for Mobile RAG Engine.
///
/// Use [MobileRag.initialize] to set up the engine, then access it
/// via [MobileRag.instance] anywhere in your app.
class MobileRag {
  static MobileRag? _instance;
  static RagEngine? _engine;

  MobileRag._();

  /// Initialize the RAG engine. Call once in main().
  ///
  /// This will:
  /// 1. Initialize the Rust library (FFI)
  /// 2. Load the tokenizer from assets
  /// 3. Load the ONNX embedding model
  /// 4. Initialize the SQLite database
  ///
  /// **Parameters:**
  ///
  /// - [tokenizerAsset] - Path to tokenizer.json in assets (e.g., `'assets/tokenizer.json'`)
  /// - [modelAsset] - Path to ONNX model file in assets (e.g., `'assets/model.onnx'`)
  /// - [databaseName] - SQLite database file name (default: `'rag.sqlite'`)
  /// - [maxChunkChars] - Maximum characters per chunk (default: 500)
  /// - [overlapChars] - Overlap between chunks for context continuity (default: 50)
  /// - [embeddingIntraOpNumThreads] - Precise thread count for ONNX (e.g., `1` for minimal CPU).
  ///   **Mutually exclusive with [threadLevel].**
  /// - [threadLevel] - High-level thread usage: `low` (~20%), `medium` (~40%), `high` (~80%).
  ///   **Mutually exclusive with [embeddingIntraOpNumThreads].**
  /// - [onProgress] - Callback for initialization progress updates
  ///
  /// **Thread Configuration:**
  ///
  /// Choose ONE of the following:
  /// - `threadLevel: ThreadUseLevel.medium` - Simple, recommended for most apps
  /// - `embeddingIntraOpNumThreads: 2` - Fine-grained control
  ///
  /// ⚠️ Setting BOTH will throw an [AssertionError].
  ///
  /// Example:
  /// ```dart
  /// await MobileRag.initialize(
  ///   tokenizerAsset: 'assets/tokenizer.json',
  ///   modelAsset: 'assets/model.onnx',
  ///   threadLevel: ThreadUseLevel.medium, // Recommended
  ///   onProgress: (status) => print(status),
  /// );
  /// ```
  static Future<void> initialize({
    required String tokenizerAsset,
    required String modelAsset,
    String? databaseName,
    int maxChunkChars = 500,
    int overlapChars = 50,
    int? embeddingIntraOpNumThreads,
    ThreadUseLevel? threadLevel,
    void Function(String status)? onProgress,
  }) async {
    if (_instance != null) {
      onProgress?.call('Already initialized');
      return;
    }

    _engine = await RagEngine.initialize(
      config: RagConfig.fromAssets(
        tokenizerAsset: tokenizerAsset,
        modelAsset: modelAsset,
        databaseName: databaseName,
        maxChunkChars: maxChunkChars,
        overlapChars: overlapChars,
        embeddingIntraOpNumThreads: embeddingIntraOpNumThreads,
        threadLevel: threadLevel,
      ),
      onProgress: onProgress,
    );
    _instance = MobileRag._();
  }

  /// **(FOR TESTING ONLY)** Inject a custom instance for mocking.
  ///
  /// This allows you to provide a mock implementation or a pre-configured
  /// engine instance in unit tests.
  @visibleForTesting
  static void setMockInstance(MobileRag? mock) {
    _instance = mock;
    if (mock != null && mock.engine != _engine) {
      _engine = mock.engine;
    }
  }

  /// Check if the engine is initialized.
  static bool get isInitialized => _instance != null;

  /// Get the singleton instance.
  ///
  /// Throws [StateError] if [initialize] has not been called.
  static MobileRag get instance {
    if (_instance == null) {
      throw StateError(
        'MobileRag not initialized. Call MobileRag.initialize() first.',
      );
    }
    return _instance!;
  }

  /// Access the underlying [RagEngine] for advanced operations.
  RagEngine get engine => _engine!;

  /// Path to the SQLite database.
  String get dbPath => _engine!.dbPath;

  /// Vocabulary size of the loaded tokenizer.
  int get vocabSize => _engine!.vocabSize;

  // ─────────────────────────────────────────────────────────────────────────
  // Convenience instance methods (delegate to RagEngine)
  // ─────────────────────────────────────────────────────────────────────────

  /// Add a document with automatic chunking and embedding.
  ///
  /// The document is split into chunks, embedded, and stored.
  ///
  /// **Note:** Indexing is **automatic** (debounced by 500ms).
  /// You generally do NOT need to call [rebuildIndex] manually, unless you want
  /// to ensure the index is ready immediately (e.g., before a UI update).
  Future<SourceAddResult> addDocument(
    String content, {
    String? metadata,
    String? name,
    String? filePath,
    ChunkingStrategy? strategy,
    Duration? chunkDelay,
    void Function(int done, int total)? onProgress,
  }) => _engine!.addDocument(
    content,
    metadata: metadata,
    name: name,
    filePath: filePath,
    strategy: strategy,
    chunkDelay: chunkDelay,
    onProgress: onProgress,
  );

  /// Get a list of all stored sources.
  Future<List<SourceEntry>> listSources() => _engine!.listSources();

  /// Remove a source and all its chunks.
  ///
  /// **Note:** You do NOT need to call [rebuildIndex] immediately.
  /// The engine uses lazy filtering to exclude deleted items from search results.
  /// However, if you delete a large amount of data (e.g., >50%), calling
  /// [rebuildIndex] is recommended to reclaim memory and optimize the vector graph.
  Future<void> removeSource(int sourceId) => _engine!.removeSource(sourceId);

  /// Search for relevant chunks and assemble context for LLM.
  Future<RagSearchResult> search(
    String query, {
    int topK = 10,
    int tokenBudget = 2000,
    ContextStrategy strategy = ContextStrategy.relevanceFirst,
    int adjacentChunks = 0,
    bool singleSourceMode = false,
    List<int>? sourceIds,
  }) => _engine!.search(
    query,
    topK: topK,
    tokenBudget: tokenBudget,
    strategy: strategy,
    adjacentChunks: adjacentChunks,
    singleSourceMode: singleSourceMode,
    sourceIds: sourceIds,
  );

  /// Hybrid search combining vector and keyword (BM25) search.
  Future<List<hybrid.HybridSearchResult>> searchHybrid(
    String query, {
    int topK = 10,
    double vectorWeight = 0.5,
    double bm25Weight = 0.5,
    List<int>? sourceIds,
  }) => _engine!.searchHybrid(
    query,
    topK: topK,
    vectorWeight: vectorWeight,
    bm25Weight: bm25Weight,
    sourceIds: sourceIds,
  );

  /// Hybrid search with context assembly for LLM.
  Future<RagSearchResult> searchHybridWithContext(
    String query, {
    int topK = 10,
    int tokenBudget = 2000,
    ContextStrategy strategy = ContextStrategy.relevanceFirst,
    int adjacentChunks = 0,
    double vectorWeight = 0.5,
    double bm25Weight = 0.5,
    bool singleSourceMode = false,
    List<int>? sourceIds,
  }) => _engine!.searchHybridWithContext(
    query,
    topK: topK,
    tokenBudget: tokenBudget,
    strategy: strategy,
    adjacentChunks: adjacentChunks,
    vectorWeight: vectorWeight,
    bm25Weight: bm25Weight,
    singleSourceMode: singleSourceMode,
    sourceIds: sourceIds,
  );

  /// Rebuild the HNSW index.
  ///
  /// **When to use:**
  /// - **Automatic:** The engine automatically rebuilds 500ms after the last operation.
  /// - **Manual:** Call this if you want to **force** an immediate rebuild (e.g., to guarantee consistency before a critical search).
  /// - **Not needed:** After `clearAllData()` (which resets everything).
  ///
  /// This operation can be slow for large datasets.
  Future<void> rebuildIndex() => _engine!.rebuildIndex();

  /// Try to load a cached HNSW index.
  ///
  /// Use this at startup to skip the expensive [rebuildIndex] step.
  /// Returns `true` if an index was successfully loaded from disk.
  Future<bool> tryLoadCachedIndex() => _engine!.tryLoadCachedIndex();

  /// Save the HNSW index marker to disk.
  ///
  /// This is handled automatically by [rebuildIndex], but can be called manually
  /// if you are doing custom index management.
  Future<void> saveIndex() => _engine!.saveIndex();

  /// Get statistics about stored sources and chunks.
  Future<SourceStats> getStats() => _engine!.getStats();

  /// Format search results as an LLM prompt.
  String formatPrompt(String query, RagSearchResult result) =>
      _engine!.formatPrompt(query, result);

  /// Clear all data (database and index files) and reset the engine.
  ///
  /// This is a destructive operation!
  Future<void> clearAllData() => _engine!.clearAllData();

  /// Dispose of resources.
  ///
  /// Call when completely done with the engine.
  static Future<void> dispose() async {
    await RagEngine.dispose();
    _engine = null;
    _instance = null;
  }
}
