# v0.1.0 - Initial Alpha Release

**Mobile RAG Engine** - On-device semantic search for Flutter

## What's Included

### Core Features
- ONNX-based embedding generation (384-dim, all-MiniLM-L6-v2 compatible)
- HNSW vector indexing for O(log n) similarity search
- SQLite-based local vector storage
- SHA256 content deduplication

### Native Performance
- Rust-powered tokenization via HuggingFace tokenizers
- Cross-platform binaries (iOS XCFramework + Android jniLibs)
- ~1ms search on 100 documents

## Pre-built Binaries

| Platform | File | Size |
|----------|------|------|
| iOS | `rust_lib_mobile_rag_engine.xcframework.zip` | 42MB |
| Android | `jniLibs.tar.gz` (arm64, armeabi-v7a, x86_64, x86) | 12MB |

## Known Limitations
- Batch embedding runs sequentially (OrtSession not thread-safe)
- Model files not included (bring your own ONNX model)
- No INT8 quantization yet

## Requirements
- Flutter 3.9+
- iOS 13.0+ / Android API 24+
- ONNX model + tokenizer.json

## Installation

```yaml
dependencies:
  mobile_rag_engine:
    git:
      url: https://github.com/dev07060/mobile_rag_engine.git
      ref: v0.1.0
```

## What's Next (v0.2.0)
- Korean model support (KoSimCSE, KR-SBERT)
- INT8 quantization
- Document chunking strategies
